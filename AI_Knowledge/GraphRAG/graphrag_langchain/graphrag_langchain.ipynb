{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG using langchain\n",
    "\n",
    "* Video tutorial [here](https://medium.com/data-science-in-your-pocket/graphrag-using-langchain-31b1ef8328b9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: LLMGraphTransformer\n",
    "\n",
    "LLMGraphTransformer: [documentation](https://api.python.langchain.com/en/latest/experimental/graph_transformers/langchain_experimental.graph_transformers.llm.LLMGraphTransformer.html#langchain_experimental.graph_transformers.llm.LLMGraphTransformer.convert_to_graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install --upgrade --quiet  json-repair networkx langchain-core langchain-google-vertexai langchain-experimental langchain-community\n",
    "\n",
    "#versions used\n",
    "langchain==0.2.8\n",
    "langchain-community==0.2.7\n",
    "langchain-core==0.2.19\n",
    "langchain-experimental==0.0.62\n",
    "langchain-google-vertexai==1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import required functions. Initialize your LLM object & reference text. Use any SOTA LLM for best results as Knowledge Graph creation is a complicated task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_google_vertexai import VertexAI \n",
    "import networkx as nx\n",
    "from langchain.chains import GraphQAChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.graphs.networkx_graph import NetworkxEntityGraph\n",
    "\n",
    "llm = VertexAI(max_output_tokens=4000,model_name='text-bison-32k')\n",
    "\n",
    "text = \"\"\"\n",
    "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "She was, in 1906, the first woman to become a professor at the University of Paris. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, we need to load this text as GraphDocuments and create a GraphTransformer object using the LLM-loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(page_content=text)]\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Its time to create the Knowledge Graph. For this, you better provide a list of entities and relationships you wish to extract else LLM might identify everything as an entity or relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer_filtered = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    ")\n",
    "graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
    "    documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you must have guessed, the above snippet creates\n",
    "\n",
    "Node = “Person”, “Country”, “Organization”\n",
    "\n",
    "Relation = [“NATIONALITY”, “LOCATED_IN”, “WORKED_AT”, “SPOUSE”]\n",
    "\n",
    "Note: Any other potential node or relation would be discarded. If you aren’t sure, you can just pass the LLM object and let the LLM decide\n",
    "\n",
    "5. We now need to create a Networkx graph and add the above-identified nodes and edges to this graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = NetworkxEntityGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for node in graph_documents_filtered[0].nodes:\n",
    "    graph.add_node(node.id)\n",
    "\n",
    "# Add edges to the graph\n",
    "for edge in graph_documents_filtered[0].relationships:\n",
    "    graph._graph.add_edge(\n",
    "            edge.source.id,\n",
    "            edge.target.id,\n",
    "            relation=edge.type,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Let’s create a GraphQAChain now that will help us to interact with the Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = GraphQAChain.from_llm(\n",
    "    llm=llm, \n",
    "    graph=graph, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Call the chain object with your query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Who is Marie Curie?\"\"\"\n",
    "chain.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: GraphIndexCreator\n",
    "\n",
    "Another approach is to use GraphIndexCreator in LangChain which is very similar to the above approach\n",
    "\n",
    "1. It first create a GraphIndexCreator using an LLM\n",
    "2. Reads text from a .txt file\n",
    "3. Creates graph using the index creator\n",
    "4. Runs the GraphQA chain on the graph similar to above approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import GraphIndexCreator\n",
    "from langchain.chains import GraphQAChain\n",
    "\n",
    "index_creator = GraphIndexCreator(llm=llm)\n",
    "\n",
    "with open(\"/home/cdsw/sample.txt\") as f:\n",
    "    all_text = f.read()\n",
    "    \n",
    "text = \"\\n\".join(all_text.split(\"\\n\\n\"))\n",
    "graph = index_creator.from_text(text)\n",
    "\n",
    "chain = GraphQAChain.from_llm(llm, graph=graph, verbose=True)\n",
    "chain.run(\"What did Pierre Curie won?\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
