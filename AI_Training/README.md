# AI Training

![Understand AI, ML & Co in Contact Centers: Definitions & Explanations](https://lh7-us.googleusercontent.com/LzEWC6dsAER9egKvQWBSQ9Sr0ig2iAwpYcrq6XNOsmjAHp0K0X5_r9wgJOrwJTnH9squ5lPXTsia45ajT450JIBEKPmzAYw9Hk-wbyXiJXRlOqu9NfHimBW_AILVWQpO-_we1p4p3GaDbep07IS_-To)

## Machine Learning

* [Course 1](https://www.coursera.org/learn/machine-learning/lecture/iYR2y/welcome-to-machine-learning): Introduction to Machnine Learning, from Standford

#### Summary

- Key ML Algorithms:
  - Linear Regression
  - Logistic Regression
  - Decision Trees, Random Forest
  - k-Nearest Neighbors (k-NN)
  - Support Vector Machines (SVM)
- Model evaluation techniques:
  - Accuracy, Precision, Recall, F1-Score
  - Confusion Matrix
  - Cross-validation
- Feature Engineering and Data Preprocessing:
  - Normalization and Standardization
  - Handling missing data
  - Feature selection
  - PCA (Principal Component Analysis): [video](https://www.youtube.com/watch?v=HMOI_lkzW08)

#### Material:

* [scikit-learn](https://scikit-learn.org/stable/): most popular python library for ML
* **VIDEO:** Training AI to Play **Pokemon** with **Reinforcement Learning**: [video](https://www.youtube.com/watch?v=DcYLT37ImBY)
* **VIDEO:** Predicting the 3D Structure of proteins with **AlphaFold2 *(in spanish)*:** [link](https://www.youtube.com/watch?v=Uz7ucmqjZ08)

## Deep Learning

* [Course 1](http://introtodeeplearning.com/): Introduction to Deep Learning, from MIT
* [Course 2](https://www.coursera.org/specializations/deep-learning): Deep Learning Specialization, from Deep Learning.AI

#### Summary:

- Key concepts:
  - Activation Functions (ReLU, Sigmoid, Tanh)
  - Forward Propagation and Backpropagation
  - Loss Functions (Mean Squared Error, Cross Entropy)
- Common Deep Learning Architectures:
  - Feedforward Neural Networks
  - Convolutional Neural Networks (CNNs)
  - Recurrent Neural Networks (RNNs)
- Optimizers (SGD, Adam, RMSprop)
- Overfitting and Regularization (Dropout, L2 Regularization)

#### Material:

* Python **notebooks** covering most of the basics of DL: [here](DeepLearning)
* **VIDEO:** What are deepfakes? [here](https://www.youtube.com/watch?v=pkF3m5wVUYI)

## NLP (Natural Language Processing)

- Key NLP tasks:
  - Text Classification
  - Named Entity Recognition (NER)
  - Machine Translation
  - Sentiment Analysis
  - Part-of-Speech Tagging
- Key techniques:
  - Bag of Words (BoW) and TF-IDF
  - Word Embeddings (Word2Vec, GloVe)
  - Tokenization, Stemming, Lemmatization
- NLP libraries: spaCy, NLTK, Hugging Face Transformers

## LLMs (Large Language Models)

![Exploring business potential of AI, LLM, ML & DL | Inwedo](https://inwedo.com/app/uploads/2023/08/llm-explained-1024x550.png)

- Introduction to LLMs (GPT, BERT, T5)
- Key Concepts:
  - Transformers Architecture
  - Self-Attention Mechanism
  - Pre-training and Fine-tuning
- Applications of LLMs:
  - Text Generation
  - Question Answering
  - Summarization
  - Conversational AI (chatbots)
- LLM fine-tuning techniques (LoRA, QLoRA, Adapter Layers)

**Transformers:** The origin of LLMs

* Original [paper](https://arxiv.org/abs/1706.03762), "Attention Is All You Need"
* [Audio summary](https://illuminate.google.com/home?pli=1&play=SKUdNc_PPLL8) of "Attention Is All You Need"
* Transformers explained: [video](https://www.youtube.com/watch?v=SZorAJ4I-sA)
* Transformers python library: [here](https://pypi.org/project/transformers/)

#### **Generative AI**

- What is Generative AI?
- Key types of generative models:
  - Generative Adversarial Networks (GANs)
  - Variational Autoencoders (VAEs)
  - Diffusion Models
- Applications:
  - Image Generation (e.g., DALL-E, Stable Diffusion)
  - Text-to-Image (Prompt Engineering)
  - Text Generation (e.g., GPT-3, GPT-4)
  - Audio Generation (e.g., Speech Synthesis)
  - Video and 3D Content Generation
